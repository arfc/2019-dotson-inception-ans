
@inproceedings{kamudaComparisonMachineLearning2018,
  location = {{Ann Arbor, MI}},
  title = {A {{Comparison}} of {{Machine Learning Methods}} for {{Automated Gamma}}-{{Ray Spectroscopy}}},
  url = {http://arfc.github.io/pres/2018-06-13-SORMA.pdf},
  abstract = {This poster outlines progress made comparing fully connected neural networks and convolution neural networks for isotope quantification in NaI gamma-ray spectra.},
  eventtitle = {Symposium on {{Radiation Measurements}} and {{Applications}} 2018},
  booktitle = {Proceedings of {{SORMA2018}}},
  date = {2018-06-13},
  author = {Kamuda, Mark},
  editora = {Zhao, Jifu and Huff, Kathryn},
  editoratype = {collaborator}
}

@unpublished{kamudaMachineLearningApproach2018,
  venue = {{Ann Arbor, MI}},
  title = {A {{Machine Learning Approach}} to {{Identifying Shielded Radioisotopes}} in {{Gamma}}-{{Ray Spectra}}},
  url = {http://arfc.github.io/pres/2018-10-31-CVT.pdf},
  abstract = {Identifying shielded sources is a challenge for gamma-ray identification algorithms. The ability to algorithmically identify shielded sources has implications for verification technologies, where shielding configurations may be unknown or unknowable to an operator. Previously, we have shown that machine learning algorithms can accurately identify and quantify isotopes in gamma-ray spectra. In this work, various machine learning algorithms are trained to identify and discriminate between shielded and unshielded isotopes in a simulated dataset of NaI spectra. Each algorithm’s performance on real and simulated gamma-ray spectra are compared.},
  type = {Poster},
  eventtitle = {Consortium for {{Verification Technology Workshop}}},
  date = {2018-10-31},
  author = {Kamuda, Mark}
}

@article{AmericanNationalStandard2016,
  title = {American {{National Standard Performance Criteria}} for {{Handheld Instruments}} for the {{Detection}} and {{Identification}} of {{Radionuclides}}},
  doi = {10.1109/IEEESTD.2016.7551091},
  abstract = {Performance specifications and testing methods for the evaluation of handheld instruments (also known as radionuclide identification devices or RIDs) used for the detection and identification of radionuclides, which emit gamma rays and, in some cases, neutrons, are contained in this standard. The specifications for general, radiological, environmental, electromagnetic and mechanical performances are given and the corresponding testing methods are described. The documentation to be provided by the manufacturer is listed as part of the requirements. Normative and informative annexes that provide guidance for the implementation of this standard are also included. (The PDF of this standard is available at no cost compliments of the Department of Homeland Security Domestic Nuclear Detection Office. http://standards.ieee.org/getN42/download/N42.34-2015.pdf).},
  journaltitle = {ANSI N42.34-2015 (Revision of ANSI N42.34-2006)},
  date = {2016-08},
  pages = {1-60},
  keywords = {neutrons,American national standard performance criteria,ANSI N42.34,ANSI N42.34-2006 Revision,ANSI N42.34-2015,ANSI standards,ANSI Standards,electromagnetic performance,environmental performance,gamma ray detection,gamma rays,Gamma rays,Handheld devices,handheld instruments,homeland security,industrial radionuclides,mechanical performance,medical radionuclides,Nuclear material,Performance evaluation,portable instruments,radiation detection,radioisotopes,radiological performance,radionuclide detection,radionuclide identification device,Radionuclides,Security,special nuclear material (SNM),testing,testing methods},
  file = {/home/samgdotson/Zotero/storage/AJ26YPIT/7551091.html}
}

@article{bergstraRandomSearchHyperParameter,
  langid = {english},
  title = {Random {{Search}} for {{Hyper}}-{{Parameter Optimization}}},
  abstract = {Grid search and manual search are the most widely used strategies for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efﬁcient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a comparison with a large previous study that used grid search and manual search to conﬁgure neural networks and deep belief networks. Compared with neural networks conﬁgured by a pure grid search, we ﬁnd that random search over the same domain is able to ﬁnd models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search ﬁnds better models by effectively searching a larger, less promising conﬁguration space. Compared with deep belief networks conﬁgured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional conﬁguration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for conﬁguring algorithms for new data sets. Our analysis casts some light on why recent “High Throughput” methods achieve surprising success—they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.},
  pages = {25},
  author = {Bergstra, James and Bengio, Yoshua},
  file = {/home/samgdotson/Zotero/storage/RKAVNGHJ/Bergstra and Bengio - Random Search for Hyper-Parameter Optimization.pdf}
}

@article{kamudaAutomatedIsotopeIdentification2017,
  title = {Automated {{Isotope Identification Algorithm Using Artificial Neural Networks}}},
  volume = {64},
  doi = {10.1109/TNS.2017.2693152},
  journaltitle = {IEEE Transactions on Nuclear Science},
  date = {2017},
  author = {Kamuda, Mark and Stinnett, John and Sullivan, Clair J.}
}

@article{kamudaAutomatedIsotopeIdentification2017a,
  title = {Automated {{Isotope Identification Algorithm Using Artificial Neural Networks}}},
  volume = {64},
  issn = {0018-9499},
  doi = {10.1109/TNS.2017.2693152},
  abstract = {There is a need to develop an algorithm that can determine the relative activities of radioisotopes in a large data set of low-resolution gamma-ray spectra that contain a mixture of many radioisotopes. Low-resolution gamma-ray spectra that contain mixtures of radioisotopes often exhibit feature overlap, requiring algorithms that can analyze these features when overlap occurs. While machine learning and pattern recognition algorithms have shown promise for the problem of radioisotope identification, their ability to identify and quantify mixtures of radioisotopes has not been studied. Because machine-learning algorithms use abstract features of the spectrum, such as the shape of overlapping peaks and Compton continuum, they are a natural choice for analyzing radioisotope mixtures. An artificial neural network (ANN) has been trained to calculate the relative activities of 32 radioisotopes in a spectrum. The ANN is trained with simulated gamma-ray spectra, allowing easy expansion of the library of target radioisotopes. In this paper, we present our initial algorithms based on an ANN and evaluate them against a series of measured and simulated spectra.},
  number = {7},
  journaltitle = {IEEE Transactions on Nuclear Science},
  date = {2017-07},
  pages = {1858-1864},
  keywords = {isotopes,ANN spectra,artificial neural network,Artificial neural network (ANN),automated isotope identification,automated radioisotope isotope identification algorithm,Compton continuum,Compton effect,gamma-ray detection,gamma-ray spectroscopy,Gamma-rays,learning (artificial intelligence),Libraries,low-resolution gamma-ray spectra,machine learning,Machine learning algorithms,machine-learning algorithm,Mathematical model,neural nets,Neurons,pattern recognition,pattern recognition algorithm,radioactivity measurement,simulated gamma-ray spectra,target radioisotope,Training},
  author = {Kamuda, M. and Stinnett, J. and Sullivan, C. J.}
}

@article{kamudaAutomatedIsotopeIdentification2018,
  title = {An {{Automated Isotope Identification}} and {{Quantification Algorithm}} for {{Isotope Mixtures}} in {{Low}}-{{Resolution Gamma}}-Ray {{Spectra}}},
  abstract = {Pattern recognition algorithms such as artificial neural networks (NNs) and convolution neural networks (CNNs) are
prime candidates to perform automated gamma-ray spectroscopy. The way these models train and operate mimics
how trained spectroscopists identify spectra. These models have shown promise in identifying gamma-ray spectra
with large calibration drift and unknown background radiation fields. In this work, two algorithms for mixtures of
radioisotopes based on NN and CNN are presented and evaluated.},
  journaltitle = {Submitted},
  date = {2018},
  author = {Kamuda, Mark and Zhao, Jifu and Huff, Kathryn}
}

@article{kamudaComparisonMachineLearning2018a,
  title = {A Comparison of Machine Learning Methods for Automated Gamma-Ray Spectroscopy},
  issn = {0168-9002},
  url = {http://www.sciencedirect.com/science/article/pii/S0168900218313779},
  doi = {10.1016/j.nima.2018.10.063},
  abstract = {Pattern recognition algorithms such as artificial neural networks (NNs) and convolution neural networks (CNNs) are prime candidates to perform automated gamma-ray spectroscopy. The way these models train and operate mimic how trained spectroscopists identify spectra. These models have shown promise in identifying gamma-ray spectra with large calibration drift and unknown background radiation fields. In this work, two algorithms for mixtures of radioisotopes based on NN and CNN are presented and evaluated.},
  journaltitle = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
  shortjournal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
  urldate = {2018-11-02},
  date = {2018-10-19},
  keywords = {Neural networks,Automated isotope identification,Gamma-ray spectroscopy},
  author = {Kamuda, Mark and Zhao, Jifu and Huff, Kathryn}
}

@article{rawool-sullivanStepsAutomatedGamma2010,
  title = {Steps {{Toward Automated Gamma Ray Spectroscopy Steps Toward Automated Gamma Ray Spectroscopy}}: {{How}} a {{Spectroscopist Deciphers}} an {{Unknown Spectrum}} to {{Reveal}} the {{Radioactive Source}}},
  shorttitle = {Steps {{Toward Automated Gamma Ray Spectroscopy Steps Toward Automated Gamma Ray Spectroscopy}}},
  abstract = {Introduction: Customs and other officials who use commercial detectors to survey materials for the presence of radioactive materials are not expert spectroscopists, and therefore sometimes are not able to conclusively identify the sources generating the signals their radiation detectors capture.},
  date = {2010-02-25},
  author = {Rawool-Sullivan, Mohini and Bounds, J.A. and Brumby, Steven and Prasad, Lakshman and Sullivan, John},
  file = {/home/samgdotson/Zotero/storage/65J5YXPH/Rawool-Sullivan et al. - 2010 - Steps Toward Automated Gamma Ray Spectroscopy Step.pdf}
}

@article{szegedyGoingDeeperConvolutions2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1409.4842},
  primaryClass = {cs},
  title = {Going {{Deeper}} with {{Convolutions}}},
  url = {http://arxiv.org/abs/1409.4842},
  abstract = {We propose a deep convolutional neural network architecture codenamed "Inception", which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
  urldate = {2019-07-01},
  date = {2014-09-16},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  file = {/home/samgdotson/Zotero/storage/P9PQP5AI/Szegedy et al. - 2014 - Going Deeper with Convolutions.pdf;/home/samgdotson/Zotero/storage/XD5668JL/1409.html}
}

@article{szegedyRethinkingInceptionArchitecture2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1512.00567},
  primaryClass = {cs},
  title = {Rethinking the {{Inception Architecture}} for {{Computer Vision}}},
  url = {http://arxiv.org/abs/1512.00567},
  abstract = {Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2\% top-1 and 5.6\% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5\% top-5 error on the validation set (3.6\% error on the test set) and 17.3\% top-1 error on the validation set.},
  urldate = {2019-07-01},
  date = {2015-12-01},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
  file = {/home/samgdotson/Zotero/storage/QCWDK39Z/Szegedy et al. - 2015 - Rethinking the Inception Architecture for Computer.pdf;/home/samgdotson/Zotero/storage/GLPT3DIJ/1512.html}
}

@inproceedings{mitchellGADRASIsotopeID2014,
  title = {{{GADRAS}} Isotope {{ID}} Users Manual for Analysis of Gamma-Ray Measurements and {{API}} for {{Linux}} and {{Android}} .},
  doi = {10.2172/1177049},
  abstract = {Isotope identification algorithms that are contained in the Gamma Detector Response and Analysis Software (GADRAS) can be used for real-time stationary measurement and search applications on platforms operating under Linux or Android operating systems. Since the background radiation can vary considerably due to variations in naturally-occurring radioactive materials (NORM), spectral algorithms can be substantially more sensitive to threat materials than search algorithms based strictly on count rate. Specific isotopes or interest can be designated for the search algorithm, which permits suppression of alarms for non-threatening sources, such as such as medical radionuclides. The same isotope identification algorithms that are used for search applications can also be used to process static measurements. The isotope identification algorithms follow the same protocols as those used by the Windows version of GADRAS, so files that are created under the Windows interface can be copied directly to processors on fielded sensors. The analysis algorithms contain provisions for gain adjustment and energy linearization, which enables direct processing of spectra as they are recorded by multichannel analyzers. Gain compensation is performed by utilizing photopeaks in background spectra. Incorporation of this energy calibration tasks into the analysis algorithm also eliminates one of the more difficult challenges associated with development of radiation detection equipment.},
  date = {2014},
  keywords = {Linux,Isotopes,Radioactivity,Android,Approximation algorithm,Background Radiation,Central processing unit,Contain (action),License,Microsoft Windows,Operating system,Protocols documentation,Radioisotopes,Real-time clock,Search algorithm,Stationary process,Zero suppression},
  author = {Mitchell, Dean James and Harding, Lee T.},
  file = {/home/samgdotson/Zotero/storage/CPRAQB8I/Mitchell and Harding - 2014 - GADRAS isotope ID users manual for analysis of gam.pdf}
}


