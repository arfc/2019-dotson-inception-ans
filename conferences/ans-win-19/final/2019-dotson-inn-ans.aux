\relax 
\citation{rawool-sullivanStepsAutomatedGamma2010}
\citation{kamudaAutomatedIsotopeIdentification2017}
\citation{kamudaComparisonMachineLearning2018a}
\citation{kamudaMachineLearningApproach2018}
\citation{mitchellGADRASIsotopeID2014}
\citation{kamudaComparisonMachineLearning2018a}
\citation{kamudaComparisonMachineLearning2018a}
\citation{kamudaComparisonMachineLearning2018a}
\citation{kamudaComparisonMachineLearning2018a}
\citation{AmericanNationalStandard2016}
\citation{szegedyGoingDeeperConvolutions2014}
\citation{szegedyRethinkingInceptionArchitecture2015}
\@writefile{toc}{\contentsline {section}{Introduction}{1}}
\@writefile{toc}{\contentsline {section}{Theory -- Artificial Neural Networks}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An arbitrary neural network that maps values with weights (arrows) \cite  {kamudaComparisonMachineLearning2018a}.\relax }}{1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:dense-nn}{{1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A single neuron being passed through an activation function, $\textit  {f}$ \cite  {kamudaComparisonMachineLearning2018a}.\relax }}{1}}
\newlabel{fig:neuron}{{2}{1}}
\citation{kamudaComparisonMachineLearning2018a}
\citation{kamudaComparisonMachineLearning2018a}
\citation{mitchellGADRASIsotopeID2014}
\citation{AmericanNationalStandard2016}
\citation{kamudaComparisonMachineLearning2018a}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A gamma spectrum shown as the input for the first inception layer.\relax }}{2}}
\newlabel{fig:inn-layer}{{3}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A zoomed out example of a full inception neural network.\relax }}{2}}
\newlabel{fig:inn-full}{{4}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces An example of a typical convolutional neural network \cite  {kamudaComparisonMachineLearning2018a}.\relax }}{2}}
\newlabel{fig:cnn}{{5}{2}}
\@writefile{toc}{\contentsline {section}{Methods}{2}}
\@writefile{toc}{\contentsline {subsection}{$\textit  {Training Set Creation}$}{2}}
\@writefile{toc}{\contentsline {subsection}{$\textit  {Network Structure and Hyperparameters}$}{2}}
\citation{bergstraRandomSearchHyperParameter}
\citation{kamudaMachineLearningApproach2018}
\citation{kamudaMachineLearningApproach2018}
\bibstyle{ans}
\bibdata{bibliography.bib}
\bibcite{rawool-sullivanStepsAutomatedGamma2010}{1}
\bibcite{kamudaAutomatedIsotopeIdentification2017}{2}
\bibcite{kamudaComparisonMachineLearning2018a}{3}
\bibcite{kamudaMachineLearningApproach2018}{4}
\bibcite{mitchellGADRASIsotopeID2014}{5}
\bibcite{AmericanNationalStandard2016}{6}
\bibcite{szegedyGoingDeeperConvolutions2014}{7}
\bibcite{szegedyRethinkingInceptionArchitecture2015}{8}
\bibcite{bergstraRandomSearchHyperParameter}{9}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Hyperparameter Space for INN\relax }}{3}}
\newlabel{tab:hyper}{{I}{3}}
\@writefile{toc}{\contentsline {subsection}{$\textit  {Benchmark Techniques}$}{3}}
\@writefile{toc}{\contentsline {section}{Conclusion}{3}}
\@writefile{toc}{\contentsline {section}{Acknowledgments}{3}}
